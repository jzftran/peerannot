{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dawid Skene with Shared Confusion Matrix (Pooled: Multinomial Model)\n",
    "Uses a single confusion matrix instead of one per worker. No need to track individual worker behavior.\n",
    "\n",
    "However, treats all workers equally reliable/unreliable.\n",
    "\n",
    "Instead of indexing by worker (pi[k, j, l]), we can use the shared confusion matrix pi[j, l].\n",
    "The probability of a task belonging to class j is computed using all worker responses at once. (So basically we have a single worker, right?)\n",
    "\n",
    "\n",
    "\n",
    "## What might be worth investigating:\n",
    "\n",
    "- `_m_step`:\n",
    "    ```python\n",
    "    np.where(denom <= 0, -1e9, denom)\n",
    "    ```\n",
    "    `-1e9` could be changed to epsilon (`np.finfo(float).eps`) or `np.maximum(denom, eps)` or something similar?\n",
    "\n",
    "- `_e_step`:\n",
    "    Maybe the e-step should rely more on log `log_T = np.log(self.rho) + (self.crowd_matrix * np.log(self.pi)).sum(axis=(1, 2))` or something similar to this.\n",
    "    Can double loop (over `i` and `j`) be solved by np.einsum?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Summing over l in y -> shape (N, J)\n",
    "sum_y_nj = np.sum(self.crowd_matrix, axis=1)  # Summing over L\n",
    "\n",
    "# Summing over n with weighting by t -> shape (K, J)\n",
    "numerator = np.dot(self.T.T, sum_y_nj)  # (K, N) @ (N, J) -> (K, J)\n",
    "\n",
    "# Summing over i (K) in the denominator\n",
    "denom = np.sum(numerator, axis=1, keepdims=True)  # (J, 1)\n",
    "\n",
    "```\n",
    "should be equivalent to:\n",
    "```python\n",
    "aggregated_votes = np.einsum(\n",
    "    \"tq, tij -> qj\", self.T, self.crowd_matrix\n",
    ")  # shape (n_classes, n_classes)\n",
    "denom = aggregated_votes.sum(\n",
    "    axis=1, keepdims=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from os import PathLike\n",
    "from sys import getsizeof\n",
    "from typing import Annotated, Generator\n",
    "\n",
    "import numpy as np\n",
    "import sparse as sp\n",
    "from annotated_types import Ge\n",
    "from loguru import logger\n",
    "from memory_profiler import profile\n",
    "from pydantic import validate_call\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from peerannot.models.template import CrowdModel,AnswersDict\n",
    "\n",
    "# load data\n",
    "from toy_data import votes, N_CLASSES, N_WORKERS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FilePathInput = PathLike | str | list[str] | Generator[str, None, None] | None\n",
    "\n",
    "\n",
    "class DawidSkeneShared(CrowdModel):\n",
    "    \"\"\"\n",
    "    =============================\n",
    "    Dawid and Skene model (1979)\n",
    "    =============================\n",
    "\n",
    "    Assumptions:\n",
    "    - independent workers\n",
    "\n",
    "    Using:\n",
    "    - EM algorithm\n",
    "\n",
    "    Estimating:\n",
    "    - One confusion matrix for each workers\n",
    "    \"\"\"\n",
    "\n",
    "    @validate_call\n",
    "    def __init__(\n",
    "        self,\n",
    "        answers: AnswersDict,\n",
    "        # TODO@jzftran probably annotation with 0 or 1 worker doesn't make sense: for 0 it should be an error\n",
    "        n_workers: Annotated[int, Ge(1)],\n",
    "        n_classes: Annotated[int, Ge(1)],\n",
    "        *,\n",
    "        sparse: bool = False,\n",
    "        path_remove: FilePathInput = None,\n",
    "    ) -> None:\n",
    "        r\"\"\"Dawid and Skene strategy: estimate confusion matrix for each worker.\n",
    "\n",
    "        Assuming that workers are independent, the model assumes that\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            (y_i^{(j)}\\ | y_i^\\\\star = k) \\\\sim \\\\mathcal{M}\\\\left(\\\\pi^{(j)}_{k,\\\\cdot}\\\\right)\n",
    "\n",
    "        and maximizes the log likelihood of the model using an EM algorithm.\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            \\\\underset{\\\\rho,\\\\\\pi,T}{\\mathrm{argmax}}\\\\prod_{i\\\\in [n_{\\\\texttt{task}}]}\\prod_{k \\\\in [K]}\\\\bigg[\\\\rho_k\\prod_{j\\\\in [n_{\\\\texttt{worker}}]}\\prod_{\\\\ell\\in [K]}\\\\big(\\\\pi^{(j)}_{k, \\\\ell}\\\\big)^{\\mathbf{1}_{\\\\{y_i^{(j)}=\\\\ell\\\\}}}\\\\bigg]^{T_{i,k}},\n",
    "\n",
    "        where :math:`\\\\rho` is the class marginals, :math:`\\\\pi` is the confusion matrix and :math:`T` is the indicator variables of belonging to each class.\n",
    "\n",
    "        :param answers: Dictionary of workers answers with format\n",
    "\n",
    "         .. code-block:: javascript\n",
    "\n",
    "            {\n",
    "                task0: {worker0: label, worker1: label},\n",
    "                task1: {worker1: label}\n",
    "            }\n",
    "\n",
    "        :type answers: dict\n",
    "        :param sparse: If the number of workers/tasks/label is large (:math:`>10^{6}` for at least one), use sparse=True to run per task\n",
    "        :type sparse: bool, optional\n",
    "        :param n_classes: Number of possible classes, defaults to 2\n",
    "        :type n_classes: int, optional\"\"\"\n",
    "\n",
    "        super().__init__(answers)\n",
    "        self.n_workers: int = n_workers\n",
    "        self.n_classes: int = n_classes\n",
    "        self.sparse: bool = sparse\n",
    "        self.path_remove: FilePathInput = path_remove\n",
    "        self.n_task: int = len(self.answers)\n",
    "\n",
    "        self.exclude_answers()\n",
    "        if self.sparse:\n",
    "            raise NotImplementedError('The sparse algorithm for DawidSkeneShared in the current context is not implemented.')\n",
    "        else:\n",
    "            self.init_crowd_matrix()\n",
    "\n",
    "    def exclude_answers(self) -> None:\n",
    "        answers_modif = {}\n",
    "        if self.path_remove is not None:\n",
    "            to_remove = np.loadtxt(self.path_remove, dtype=int)\n",
    "            i = 0\n",
    "            for key, val in self.answers.items():\n",
    "                if int(key) not in to_remove[:, 1]:\n",
    "                    answers_modif[i] = val\n",
    "                    i += 1\n",
    "            self.answers = answers_modif\n",
    "\n",
    "\n",
    "    def init_crowd_matrix(self)->None:\n",
    "        \"\"\"Transform dictionnary of labels to a tensor of size (n_task, n_workers, n_classes).\"\"\"\n",
    "\n",
    "        matrix = np.zeros((self.n_task, self.n_workers, self.n_classes))\n",
    "        for task, ans in self.answers.items():\n",
    "            for worker, label in ans.items():\n",
    "                matrix[task, worker, label] += 1\n",
    "\n",
    "        logger.info(f\"Dense crowd matrix  {getsizeof(matrix)}\")\n",
    "        # shape\n",
    "        self.crowd_matrix = matrix\n",
    "\n",
    "    def init_T(self):\n",
    "        \"\"\"NS initialization\"\"\"\n",
    "        # shape (n_task, n_workers)\n",
    "        T = self.crowd_matrix.sum(axis=1)\n",
    "        logger.info(f\"Size of T before calc: {getsizeof(T)}\")\n",
    "\n",
    "        tdim = T.sum(1, keepdims=True)\n",
    "        self.T = np.where(tdim > 0, T / tdim, 0)\n",
    "        logger.info(f\"Size of T: {getsizeof(self.T)}\")\n",
    "\n",
    "    def _m_step(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        \"\"\"Maximizing log likelihood (see eq. 2.3 and 2.4 Dawid and Skene 1979)\n",
    "\n",
    "        Returns:\n",
    "            :math:`\\\\rho`: :math:`(\\\\rho_j)_j` probabilities that instance has true response j if drawn at random (class marginals)\n",
    "            pi: number of times worker k records l when j is correct\n",
    "        \"\"\"\n",
    "        self.rho = self.T.sum(0) / self.n_task\n",
    "\n",
    "        aggregated_votes = np.einsum(\n",
    "            \"tq, tij -> qj\", self.T, self.crowd_matrix\n",
    "        )  # shape (n_classes, n_classes)\n",
    "        denom = aggregated_votes.sum(\n",
    "            axis=1, keepdims=True\n",
    "        )\n",
    "        # self.shared_pi = aggregated_votes/ np.where(denom <=0, -1e9, denom).reshape(-1,1)\n",
    "        self.shared_pi = np.where(denom > 0, aggregated_votes / denom, 0)\n",
    "        \n",
    "    def _e_step(self) -> None:\n",
    "        \"\"\"Estimate indicator variables using a shared confusion matrix\"\"\"\n",
    "\n",
    "        T = np.zeros((self.n_task, self.n_classes))\n",
    "\n",
    "        for i in range(self.n_task):\n",
    "            for j in range(self.n_classes):\n",
    "                num = (\n",
    "                    np.prod(\n",
    "                        np.power(\n",
    "                            self.shared_pi[j, :], self.crowd_matrix[i, :, :]\n",
    "                        )\n",
    "                    )\n",
    "                    * self.rho[j]\n",
    "                )\n",
    "                T[i, j] = num\n",
    "\n",
    "\n",
    "        self.denom_e_step = T.sum(axis=1, keepdims=True)\n",
    "        self.T = np.where(self.denom_e_step > 0, T / self.denom_e_step, T)\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        \"\"\"Compute log likelihood of the model\"\"\"\n",
    "        return np.log(np.sum(self.denom_e_step))\n",
    "\n",
    "    def run_dense(\n",
    "        self,\n",
    "        epsilon: Annotated[float, Ge(0)] = 1e-6,\n",
    "        maxiter: Annotated[int, Ge(0)] = 50,\n",
    "        *,\n",
    "        verbose: bool = False,\n",
    "    ) -> tuple[list[np.float64], int]:\n",
    "        i = 0\n",
    "        eps = np.inf\n",
    "\n",
    "        self.init_T()\n",
    "        ll = []\n",
    "        pbar = tqdm(total=maxiter, desc=\"Dawid and Skene\")\n",
    "        while i < maxiter and eps > epsilon:\n",
    "            self._m_step()\n",
    "            self._e_step()\n",
    "            likeli = self.log_likelihood()\n",
    "            ll.append(likeli)\n",
    "            if len(ll) >= 2:\n",
    "                eps = np.abs(ll[-1] - ll[-2])\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.set_description(\"Finished\")\n",
    "        pbar.close()\n",
    "        self.c = i\n",
    "        if eps > epsilon and verbose:\n",
    "            print(f\"DS did not converge: err={eps}\")\n",
    "        return ll, i\n",
    "\n",
    "\n",
    "    @validate_call\n",
    "    def run(\n",
    "        self,\n",
    "        epsilon: Annotated[float, Ge(0)] = 1e-6,\n",
    "        maxiter: Annotated[int, Ge(0)] = 50,\n",
    "        *,\n",
    "        verbose: bool = False,\n",
    "    ) -> tuple[list[np.float64], int]:\n",
    "        \"\"\"Run the EM optimization\n",
    "\n",
    "        :param epsilon: stopping criterion (:math:`\\\\ell_1` norm between two iterates of log likelihood), defaults to 1e-6\n",
    "        :type epsilon: float, optional\n",
    "        :param maxiter: Maximum number of steps, defaults to 50\n",
    "        :type maxiter: int, optional\n",
    "        :param verbose: Verbosity level, defaults to False\n",
    "        :type verbose: bool, optional\n",
    "        :return: Log likelihood values and number of steps taken\n",
    "        :rtype: (list,int)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.sparse:\n",
    "            raise NotImplementedError('The sparse algorithm for DawidSkeneShared in the current context is not implemented.')\n",
    "        return self.run_dense(\n",
    "            epsilon=epsilon,\n",
    "            maxiter=maxiter,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "    def get_answers(self):\n",
    "        \"\"\"Get most probable labels\"\"\"\n",
    "        if self.sparse:\n",
    "            return np.vectorize(self.inv_labels.get)(\n",
    "                sp.argmax(self.sparse_T, axis=1).todense()\n",
    "            )\n",
    "        return np.vectorize(self.inv_labels.get)(\n",
    "            np.argmax(self.get_probas(), axis=1)\n",
    "        )\n",
    "\n",
    "    def get_probas(self):\n",
    "        \"\"\"Get soft labels distribution for each task\"\"\"\n",
    "        if self.sparse:\n",
    "            warnings.warn(\"Sparse implementation only returns hard labels\")\n",
    "            return self.get_answers()\n",
    "        return self.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-19 14:08:45.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_crowd_matrix\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mDense crowd matrix  5904\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dss = DawidSkeneShared(answers=votes, n_workers=N_WORKERS, n_classes=N_CLASSES, sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-19 14:08:46.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mSize of T before calc: 1568\u001b[0m\n",
      "\u001b[32m2025-03-19 14:08:46.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mSize of T: 1568\u001b[0m\n",
      "Finished:  61%|██████    | 61/100 [00:00<00:00, 322.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([np.float64(-0.027586772757028165),\n",
       "  np.float64(-0.04577618296861183),\n",
       "  np.float64(-0.027089862546890126),\n",
       "  np.float64(-0.007047782094224704),\n",
       "  np.float64(0.002385997332072406),\n",
       "  np.float64(0.005258957474095518),\n",
       "  np.float64(0.00689830431052444),\n",
       "  np.float64(0.008151101246933223),\n",
       "  np.float64(0.00919250268013707),\n",
       "  np.float64(0.010164030187279821),\n",
       "  np.float64(0.011195333568343138),\n",
       "  np.float64(0.012400123406574684),\n",
       "  np.float64(0.013807222652733637),\n",
       "  np.float64(0.015235613815202017),\n",
       "  np.float64(0.016361922718117344),\n",
       "  np.float64(0.017075935584952434),\n",
       "  np.float64(0.017530719713185882),\n",
       "  np.float64(0.017887639872181036),\n",
       "  np.float64(0.018231767162021358),\n",
       "  np.float64(0.018602405750528638),\n",
       "  np.float64(0.019020924380967762),\n",
       "  np.float64(0.019503528820936436),\n",
       "  np.float64(0.020066211474956956),\n",
       "  np.float64(0.020726305053762717),\n",
       "  np.float64(0.021502294725816083),\n",
       "  np.float64(0.02241229060096038),\n",
       "  np.float64(0.02347118201173101),\n",
       "  np.float64(0.024686619355934997),\n",
       "  np.float64(0.026054458760104898),\n",
       "  np.float64(0.027554973555986184),\n",
       "  np.float64(0.029151573363129443),\n",
       "  np.float64(0.030793428257586568),\n",
       "  np.float64(0.03242204190688903),\n",
       "  np.float64(0.03398002844197363),\n",
       "  np.float64(0.03541930135953487),\n",
       "  np.float64(0.03670633605204281),\n",
       "  np.float64(0.0378236921621636),\n",
       "  np.float64(0.0387684484490975),\n",
       "  np.float64(0.03954887315645878),\n",
       "  np.float64(0.040180577779375976),\n",
       "  np.float64(0.040682996799276165),\n",
       "  np.float64(0.04107661762294396),\n",
       "  np.float64(0.04138107329305548),\n",
       "  np.float64(0.04161401866917414),\n",
       "  np.float64(0.041790619224857564),\n",
       "  np.float64(0.04192346218219275),\n",
       "  np.float64(0.042022722773516485),\n",
       "  np.float64(0.04209645898003499),\n",
       "  np.float64(0.042150949574583985),\n",
       "  np.float64(0.042191024486190984),\n",
       "  np.float64(0.04222036113604435),\n",
       "  np.float64(0.04224173636557911),\n",
       "  np.float64(0.04225723293892174),\n",
       "  np.float64(0.0422684044508545),\n",
       "  np.float64(0.04227640450080411),\n",
       "  np.float64(0.04228208640658073),\n",
       "  np.float64(0.04228607931210578),\n",
       "  np.float64(0.04228884576533562),\n",
       "  np.float64(0.042290724972417836),\n",
       "  np.float64(0.04229196510824711),\n",
       "  np.float64(0.04229274734166182)],\n",
       " 61)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss.run(maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 1, 4, 0, 5, 3, 7, 8, 0, 5, 8, 5, 4, 7, 4, 7, 5, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss.get_answers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
