{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dawid-Skene Algorithm using the diagonal of the confucion matrix\n",
    "\n",
    "if we use the diagonal of the confusion matrix $\\pi$ we assume:\n",
    "- annotators only have a probabilty of labeling the correct class correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import super small toy dataset\n",
    "from simple_toy_data import votes as svotes, N_WORKERS as sN_WORKERS, N_CLASSES as sN_CLASSES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# those are equivalent\n",
    "pij = np.einsum(\"j,jil->il\", dsd.T[:,1], dsd.crowd_matrix) \n",
    "pij = dsd.T[:, 1] @ dsd.crowd_matrix.transpose((1, 0, 2))\n",
    "# then denomiator:\n",
    "denom = np.einsum(\"j,jil->i\", dsd.T[:,1], dsd.crowd_matrix) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jozef/Desktop/repos/peerannot/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from os import PathLike\n",
    "from sys import getsizeof\n",
    "from typing import Annotated, Generator\n",
    "\n",
    "import numpy as np\n",
    "import sparse as sp\n",
    "from annotated_types import Ge\n",
    "from loguru import logger\n",
    "from memory_profiler import profile\n",
    "from pydantic import validate_call\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from peerannot.models.template import CrowdModel,AnswersDict\n",
    "from peerannot.models import DawidSkene\n",
    "# load data\n",
    "from toy_data import votes, N_CLASSES, N_WORKERS\n",
    "\n",
    "from types import MethodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DawidSkeneDiagonal(DawidSkene):\n",
    "    \"\"\"\n",
    "    =============================\n",
    "    Dawid and Skene model (1979)\n",
    "    =============================\n",
    "\n",
    "    Assumptions:\n",
    "    - independent workers\n",
    "\n",
    "    Using:\n",
    "    - EM algorithm\n",
    "\n",
    "    Estimating:\n",
    "    - Different diagonal matrix for each worker\n",
    "    \"\"\"\n",
    "\n",
    "    def _m_step(self) -> None:\n",
    "        \"\"\"Maximizing log likelihood with only diagonal elements of pi.\"\"\"\n",
    "        rho = self.T.sum(0) / self.n_task\n",
    "\n",
    "        pi = np.zeros((self.n_workers, self.n_classes))\n",
    "        for j in range(self.n_classes):\n",
    "            # TODO:@jzftran change this to calculate diagonal faster\n",
    "            pij = self.T[:, j] @ self.crowd_matrix.transpose((1, 0, 2))\n",
    "            denom = pij.sum(1)\n",
    "\n",
    "\n",
    "            diag_values = pij[:, j] / np.where(denom > 0, denom, 1e-9)\n",
    "            pi[:, j] = diag_values\n",
    "\n",
    "\n",
    "        # pi shape (n_workers, n_class), reresents how sure worker is sure that the label j is true\n",
    "        pi_non_diag_values = (np.ones_like(pi) - pi) / (self.n_classes - 1)\n",
    "        self.rho, self.pi, self.pi_non_diag_values = rho, pi, pi_non_diag_values\n",
    "\n",
    "\n",
    "    def _e_step(self) -> None:\n",
    "        \"\"\"Estimate indicator variables (see eq. 2.5 Dawid and Skene 1979)\n",
    "\n",
    "        Returns:\n",
    "            T: New estimate for indicator variables (n_task, n_worker)\n",
    "            denom: value used to compute likelihood easily\n",
    "        \"\"\"\n",
    "        T = np.zeros((self.n_task, self.n_classes))\n",
    "\n",
    "        worker_probs = np.zeros(self.n_workers)\n",
    "        \n",
    "        for i in range(self.n_task):\n",
    "            for j in range(self.n_classes):\n",
    "                # Compute per-worker probabilities\n",
    "                for k in range(self.n_workers):\n",
    "                    # Worker k's annotations for task i\n",
    "                    worker_labels = self.crowd_matrix[i, k, :]  # shape (n_classes,)\n",
    "                    \n",
    "                    # Extract the diagonal and off-diagonal contributions\n",
    "                    diag_contrib = np.power( self.pi[k, j], worker_labels[j])  # When label j is actually assigned\n",
    "                    off_diag_contrib = np.prod(\n",
    "                        np.power(self.pi_non_diag_values[k, j] , worker_labels[np.arange(self.n_classes) != j])\n",
    "                    )\n",
    "\n",
    "                    worker_probs[k] = diag_contrib * off_diag_contrib\n",
    "\n",
    "                num = np.prod(worker_probs) * self.rho[j]\n",
    "                T[i, j] = num\n",
    "\n",
    "        self.denom_e_step = T.sum(1, keepdims=True)\n",
    "        T = np.where(self.denom_e_step > 0, T / self.denom_e_step, T)\n",
    "        self.T = T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 10:17:05.547\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_crowd_matrix\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mDense crowd matrix  5904\u001b[0m\n",
      "\u001b[32m2025-03-25 10:17:05.549\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m103\u001b[0m - \u001b[34m\u001b[1mSize of T before calc: 1568\u001b[0m\n",
      "\u001b[32m2025-03-25 10:17:05.550\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m107\u001b[0m - \u001b[34m\u001b[1mSize of T: 1568\u001b[0m\n",
      "Finished:  59%|█████▉    | 59/100 [00:00<00:00, 112.91it/s]       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 1, 4, 0, 5, 3, 7, 1, 0, 3, 1, 3, 4, 7, 4, 7, 3, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd = DawidSkeneDiagonal(\n",
    "    answers=votes, n_workers=N_WORKERS, n_classes=N_CLASSES, sparse=False\n",
    ")\n",
    "dsd.run(maxiter=100)\n",
    "dsd.get_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fastes implementation\n",
    "def _e_step(self) -> None:\n",
    "    \"\"\"Vectorized implementation of e-step without worker loops.\"\"\"\n",
    "    # Compute diagonal contributions\n",
    "    # shape: (n_task, n_workers, n_classes)\n",
    "    diag_contrib = np.power(\n",
    "        self.pi[np.newaxis, :, :],  # (1, n_workers, n_classes)\n",
    "        self.crowd_matrix  # (n_task, n_workers, n_classes)\n",
    "    )\n",
    "    \n",
    "    # Compute off-diagonal contributions\n",
    "    # For each class j, we need to multiply pi_non_diag_values[k,j]^worker_labels[l] for all l != j\n",
    "    mask = 1 - np.eye(self.n_classes)  # (n_casses, n_classes)\n",
    "    \n",
    "    # shape: (n_task, n_workers, n_classes, n_classes)\n",
    "    off_diag_powers = np.power(\n",
    "        self.pi_non_diag_values[np.newaxis, :, np.newaxis, :],  # (1, n_workers, 1, n_classes)\n",
    "        self.crowd_matrix[:, :, :, np.newaxis] * mask[np.newaxis, np.newaxis, :, :]\n",
    "    )\n",
    "    \n",
    "    off_diag_contrib = np.prod(off_diag_powers, axis=2)  # (n_task, n_workers, n_classes)\n",
    "    \n",
    "    worker_probs = diag_contrib * off_diag_contrib\n",
    "    \n",
    "    T = np.prod(worker_probs, axis=1) * self.rho[np.newaxis, :]  # (n_task, n_classes)\n",
    "    \n",
    "    self.denom_e_step = T.sum(axis=1, keepdims=True)\n",
    "    self.T = np.where(self.denom_e_step > 0, T / self.denom_e_step, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 10:17:12.107\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m103\u001b[0m - \u001b[34m\u001b[1mSize of T before calc: 1568\u001b[0m\n",
      "\u001b[32m2025-03-25 10:17:12.108\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m107\u001b[0m - \u001b[34m\u001b[1mSize of T: 1568\u001b[0m\n",
      "Finished:  59%|█████▉    | 59/100 [00:00<00:00, 3013.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 1, 4, 0, 5, 3, 7, 1, 0, 3, 1, 3, 4, 7, 4, 7, 3, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd._e_step = MethodType(_e_step, dsd)\n",
    "dsd.run(maxiter=100)\n",
    "dsd.get_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bit faster, but not as memory efficient\n",
    "def _e_step(self) -> None:\n",
    "    T = np.zeros((self.n_task, self.n_classes))\n",
    "    \n",
    "    pi = self.pi.T  # (n_classes, n_workers)\n",
    "    pi_non_diag = self.pi_non_diag_values.T  # (n_classes, n_workers)\n",
    "    \n",
    "    for j in range(self.n_classes):\n",
    "        # Diagonal contributions for class j\n",
    "        # shape: (n_task, n_workers)\n",
    "        diag_contrib = np.power(pi[j], self.crowd_matrix[:, :, j])\n",
    "        \n",
    "        # Off-diagonal contributions for class j\n",
    "        # Create mask for other classes\n",
    "        other_classes = np.arange(self.n_classes) != j\n",
    "        # shape: (n_task, n_workers, n_classes-1)\n",
    "        off_diag_contrib = self.crowd_matrix[:, :, other_classes]\n",
    "        # shape: (n_workers, n_classes-1)\n",
    "        other_probs = pi_non_diag[j][:, np.newaxis]  # Broadcast to non-j classes\n",
    "        \n",
    "        # shape: (n_task, n_workers)\n",
    "        off_diag_contrib = np.prod(\n",
    "            np.power(other_probs, off_diag_contrib),\n",
    "            axis=2\n",
    "        )\n",
    "        \n",
    "        # shape: (n_task,)\n",
    "        class_probs = np.prod(diag_contrib * off_diag_contrib, axis=1) * self.rho[j]\n",
    "        T[:, j] = class_probs\n",
    "    \n",
    "    self.denom_e_step = T.sum(axis=1, keepdims=True)\n",
    "    self.T = np.where(self.denom_e_step > 0, T / self.denom_e_step, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 10:17:24.761\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m103\u001b[0m - \u001b[34m\u001b[1mSize of T before calc: 1568\u001b[0m\n",
      "\u001b[32m2025-03-25 10:17:24.762\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m107\u001b[0m - \u001b[34m\u001b[1mSize of T: 1568\u001b[0m\n",
      "Finished:  59%|█████▉    | 59/100 [00:00<00:00, 1747.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 1, 4, 0, 5, 3, 7, 1, 0, 3, 1, 3, 4, 7, 4, 7, 3, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd._e_step = MethodType(_e_step, dsd)\n",
    "dsd.run(maxiter=100)\n",
    "dsd.get_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be comperable to Tanguy's implementation\n",
    "def _e_step(self) -> None:\n",
    "    \"\"\"Vectorized E-step keeping task/class loops, vectorizing worker computations.\"\"\"\n",
    "    T = np.zeros((self.n_task, self.n_classes))\n",
    "    \n",
    "    for i in range(self.n_task):\n",
    "        for j in range(self.n_classes):\n",
    "            # Get all worker labels for task i (n_workers, n_classes)\n",
    "            worker_labels = self.crowd_matrix[i]  # shape (n_workers, n_classes)\n",
    "\n",
    "            # Vectorized computation for all workers simultaneously\n",
    "            # Diagonal contributions: pi[k,j]^worker_labels[k,j]\n",
    "            diag_contrib = np.power(self.pi[:, j], worker_labels[:, j])  # shape (n_workers,)\n",
    "\n",
    "            # Off-diagonal contributions: product over l≠j of pi_non_diag[k,j]^worker_labels[k,l]\n",
    "            mask = np.ones(self.n_classes, dtype=bool)\n",
    "            mask[j] = False  # exclude current class j\n",
    "            off_diag_labels = worker_labels[:, mask]  # shape (n_workers, n_classes-1)\n",
    "\n",
    "            off_diag_contrib = np.prod(\n",
    "                np.power(self.pi_non_diag_values[:, j][:, np.newaxis], off_diag_labels),\n",
    "                axis=1\n",
    "            )  # shape (n_workers,)\n",
    "\n",
    "            # Combine contributions\n",
    "            worker_probs = diag_contrib * off_diag_contrib  # shape (n_workers,)\n",
    "            T[i, j] = np.prod(worker_probs) * self.rho[j]\n",
    "\n",
    "    self.denom_e_step = T.sum(1, keepdims=True)\n",
    "    self.T = np.where(self.denom_e_step > 0, T / self.denom_e_step, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 10:17:30.142\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m103\u001b[0m - \u001b[34m\u001b[1mSize of T before calc: 1568\u001b[0m\n",
      "\u001b[32m2025-03-25 10:17:30.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit_T\u001b[0m:\u001b[36m107\u001b[0m - \u001b[34m\u001b[1mSize of T: 1568\u001b[0m\n",
      "Finished:  59%|█████▉    | 59/100 [00:00<00:00, 219.66it/s]       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 1, 4, 0, 5, 3, 7, 1, 0, 3, 1, 3, 4, 7, 4, 7, 3, 7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd._e_step = MethodType(_e_step, dsd)\n",
    "dsd.run(maxiter=100)\n",
    "dsd.get_answers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
