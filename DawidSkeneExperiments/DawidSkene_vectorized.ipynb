{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "from toy_data import N_CLASSES, N_WORKERS, votes\n",
    "\n",
    "from peerannot.models import DawidSkene\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 11:20:34.153\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_init_crowd_matrix\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mDense crowd matrix  5904\u001b[0m\n",
      "\u001b[32m2025-04-03 11:20:34.154\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[34m\u001b[1mDense Crowd matrix5904\u001b[0m\n",
      "\u001b[32m2025-04-03 11:20:34.154\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_init_T\u001b[0m:\u001b[36m113\u001b[0m - \u001b[34m\u001b[1mSize of T before calc: 1568\u001b[0m\n",
      "\u001b[32m2025-04-03 11:20:34.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_init_T\u001b[0m:\u001b[36m117\u001b[0m - \u001b[34m\u001b[1mSize of T: 1568\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220761f06543435eaf96a2575af9de21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dawid and Skene:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 1, 4, 0, 5, 3, 7, 1, 0, 3, 8, 3, 4, 7, 4, 7, 3, 7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DawidSkene(votes, N_WORKERS, N_CLASSES)\n",
    "ds.run(maxiter=70)\n",
    "ds.get_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections.abc import Generator\n",
    "from os import PathLike\n",
    "from sys import getsizeof\n",
    "from typing import Annotated\n",
    "\n",
    "import numpy as np\n",
    "from annotated_types import Ge\n",
    "from loguru import logger\n",
    "from numpy.typing import NDArray\n",
    "from pydantic import validate_call\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from peerannot.models.aggregation.warnings import DidNotConverge\n",
    "from peerannot.models.template import AnswersDict, CrowdModel\n",
    "\n",
    "FilePathInput = PathLike | str | list[str] | Generator[str, None, None] | None\n",
    "\n",
    "\n",
    "class DawidSkene(CrowdModel):\n",
    "    \"\"\"\n",
    "    =============================\n",
    "    Dawid and Skene model (1979)\n",
    "    =============================\n",
    "\n",
    "    Assumptions:\n",
    "    - independent workers\n",
    "\n",
    "    Using:\n",
    "    - EM algorithm\n",
    "\n",
    "    Estimating:\n",
    "    - One confusion matrix for each workers\n",
    "    \"\"\"\n",
    "\n",
    "    @validate_call\n",
    "    def __init__(\n",
    "        self,\n",
    "        answers: AnswersDict,\n",
    "        n_workers: Annotated[int, Ge(1)],\n",
    "        n_classes: Annotated[int, Ge(1)],\n",
    "        *,\n",
    "        path_remove: FilePathInput = None,\n",
    "    ) -> None:\n",
    "        r\"\"\"Dawid and Skene strategy: estimate confusion matrix for each worker.\n",
    "\n",
    "        Assuming that workers are independent, the model assumes that\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            (y_i^{(j)}\\ | y_i^\\\\star = k) \\\\sim \\\\mathcal{M}\\\\left(\\\\pi^{(j)}_{k,\\\\cdot}\\\\right)\n",
    "\n",
    "        and maximizes the log likelihood of the model using an EM algorithm.\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            \\\\underset{\\\\rho,\\\\\\pi,T}{\\mathrm{argmax}}\\\\prod_{i\\\\in [n_{\\\\texttt{task}}]}\\prod_{k \\\\in [K]}\\\\bigg[\\\\rho_k\\prod_{j\\\\in [n_{\\\\texttt{worker}}]}\\prod_{\\\\ell\\in [K]}\\\\big(\\\\pi^{(j)}_{k, \\\\ell}\\\\big)^{\\mathbf{1}_{\\\\{y_i^{(j)}=\\\\ell\\\\}}}\\\\bigg]^{T_{i,k}},\n",
    "\n",
    "        where :math:`\\\\rho` is the class marginals, :math:`\\\\pi` is the confusion matrix and :math:`T` is the indicator variables of belonging to each class.\n",
    "\n",
    "        :param answers: Dictionary of workers answers with format\n",
    "\n",
    "         .. code-block:: javascript\n",
    "\n",
    "            {\n",
    "                task0: {worker0: label, worker1: label},\n",
    "                task1: {worker1: label}\n",
    "            }\n",
    "\n",
    "        :type answers: dict\n",
    "        :param sparse: If the number of workers/tasks/label is large (:math:`>10^{6}` for at least one), # use sparse=True to run per task\n",
    "        :param n_classes: Number of possible classes, defaults to 2\n",
    "        :type n_classes: int, optional\"\"\"\n",
    "\n",
    "        super().__init__(answers)\n",
    "        self.n_workers: int = n_workers\n",
    "        self.n_classes: int = n_classes\n",
    "        self.path_remove: FilePathInput = path_remove\n",
    "        self.n_task: int = len(self.answers)\n",
    "\n",
    "        self._exclude_answers()\n",
    "\n",
    "        self._init_crowd_matrix()\n",
    "        logger.debug(f\"Dense Crowd matrix{getsizeof(self.crowd_matrix)}\")\n",
    "\n",
    "    def _exclude_answers(self) -> None:\n",
    "        answers_modif = {}\n",
    "        if self.path_remove is not None:\n",
    "            to_remove = np.loadtxt(self.path_remove, dtype=int)\n",
    "            i = 0\n",
    "            for key, val in self.answers.items():\n",
    "                if int(key) not in to_remove[:, 1]:\n",
    "                    answers_modif[i] = val\n",
    "                    i += 1\n",
    "            self.answers = answers_modif\n",
    "\n",
    "    def _init_crowd_matrix(self) -> None:\n",
    "        \"\"\"Transform dictionnary of labels to a tensor of size\n",
    "        (n_task, n_workers, n_classes).\"\"\"\n",
    "\n",
    "        matrix = np.zeros((self.n_task, self.n_workers, self.n_classes))\n",
    "        for task, ans in self.answers.items():\n",
    "            for worker, label in ans.items():\n",
    "                matrix[task, worker, label] += 1\n",
    "\n",
    "        logger.debug(f\"Dense crowd matrix  {getsizeof(matrix)}\")\n",
    "        self.crowd_matrix = matrix\n",
    "\n",
    "    def _init_T(self) -> None:  # noqa: N802\n",
    "        \"\"\"NS initialization\"\"\"\n",
    "        # T shape is n_task, n_classes\n",
    "        T = self.crowd_matrix.sum(axis=1)  # noqa: N806\n",
    "        logger.debug(f\"Size of T before calc: {getsizeof(T)}\")\n",
    "\n",
    "        tdim = T.sum(1, keepdims=True)\n",
    "        self.T = np.where(tdim > 0, T / tdim, 0)\n",
    "        logger.debug(f\"Size of T: {getsizeof(self.T)}\")\n",
    "\n",
    "    def _m_step(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        \"\"\"Maximizing log likelihood (see eq. 2.3 and 2.4 Dawid and Skene 1979)\n",
    "\n",
    "        Returns:\n",
    "            :math:`\\\\rho`: :math:`(\\\\rho_j)_j` probabilities that instance has\n",
    "                true response j if drawn at random (class marginals)\n",
    "            pi: number of times worker k records l when j is correct\n",
    "        \"\"\"\n",
    "        rho = self.T.sum(0) / self.n_task\n",
    "\n",
    "        pi = np.zeros((self.n_workers, self.n_classes, self.n_classes))\n",
    "        for q in range(self.n_classes):\n",
    "            pij = self.T[:, q] @ self.crowd_matrix.transpose((1, 0, 2))\n",
    "            denom = pij.sum(1)\n",
    "            pi[:, q, :] = pij / np.where(denom <= 0, -1e9, denom).reshape(\n",
    "                -1,\n",
    "                1,\n",
    "            )\n",
    "        self.rho, self.pi = rho, pi\n",
    "\n",
    "    def _e_step(self) -> None:\n",
    "        \"\"\"Estimate indicator variables (see eq. 2.5 Dawid and Skene 1979)\"\"\"\n",
    "\n",
    "        exp_pi = np.power(self.pi[np.newaxis, :, :, :], self.crowd_matrix[:, :, np.newaxis, :])\n",
    "\n",
    "        # numerator by taking the product over the worker axis\n",
    "        num = np.prod(exp_pi, axis=3).prod(axis=1) * self.rho[np.newaxis, :]\n",
    "        self.denom_e_step = num.sum(axis=1, keepdims=True)\n",
    "        self.T = np.where(self.denom_e_step > 0, num / self.denom_e_step, num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _log_likelihood(self) -> float:\n",
    "        \"\"\"Compute log likelihood of the model\"\"\"\n",
    "        return np.log(np.sum(self.denom_e_step))\n",
    "\n",
    "    @validate_call\n",
    "    def run(\n",
    "        self,\n",
    "        epsilon: Annotated[float, Ge(0)] = 1e-6,\n",
    "        maxiter: Annotated[int, Ge(0)] = 50,\n",
    "    ) -> tuple[list[float], int]:\n",
    "        \"\"\"Run the EM optimization\n",
    "\n",
    "        :param epsilon: stopping criterion (:math:`\\\\ell_1` norm between two iterates of log likelihood), defaults to 1e-6\n",
    "        :type epsilon: float, optional\n",
    "        :param maxiter: Maximum number of steps, defaults to 50\n",
    "        :type maxiter: int, optional\n",
    "        :param verbose: Verbosity level, defaults to False\n",
    "        :return: Log likelihood values and number of steps taken\n",
    "        :rtype: (list,int)\n",
    "        \"\"\"\n",
    "\n",
    "        i = 0\n",
    "        eps = np.inf\n",
    "\n",
    "        self._init_T()\n",
    "        ll = []\n",
    "        pbar = tqdm(total=maxiter, desc=\"Dawid and Skene\")\n",
    "        while i < maxiter and eps > epsilon:\n",
    "            self._m_step()\n",
    "            self._e_step()\n",
    "            likeli = self._log_likelihood()\n",
    "            ll.append(likeli)\n",
    "            if i > 0:\n",
    "                eps = np.abs(ll[-1] - ll[-2])\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.set_description(\"Finished\")\n",
    "        pbar.close()\n",
    "        self.c = i\n",
    "        if eps > epsilon:\n",
    "            warnings.warn(\n",
    "                DidNotConverge(self.__class__.__name__, eps, epsilon),\n",
    "                stacklevel=2,\n",
    "            )\n",
    "\n",
    "        return ll, i\n",
    "\n",
    "    def get_answers(self) -> NDArray:\n",
    "        \"\"\"Get most probable labels\"\"\"\n",
    "\n",
    "        return np.vectorize(self.inv_labels.get)(\n",
    "            np.argmax(self.get_probas(), axis=1),\n",
    "        )\n",
    "\n",
    "    def get_probas(self) -> NDArray:\n",
    "        \"\"\"Get soft labels distribution for each task\"\"\"\n",
    "        return self.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 11:20:42.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_init_crowd_matrix\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mDense crowd matrix  5904\u001b[0m\n",
      "\u001b[32m2025-04-03 11:20:42.922\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[34m\u001b[1mDense Crowd matrix5904\u001b[0m\n",
      "\u001b[32m2025-04-03 11:20:42.923\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_init_T\u001b[0m:\u001b[36m113\u001b[0m - \u001b[34m\u001b[1mSize of T before calc: 1568\u001b[0m\n",
      "\u001b[32m2025-04-03 11:20:42.923\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_init_T\u001b[0m:\u001b[36m117\u001b[0m - \u001b[34m\u001b[1mSize of T: 1568\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cc6293baf94948b4606d4de698fc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dawid and Skene:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 1, 4, 0, 5, 3, 7, 1, 0, 3, 8, 3, 4, 7, 4, 7, 3, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DawidSkene(votes, N_WORKERS, N_CLASSES)\n",
    "ds.run(maxiter=70)\n",
    "ds.get_answers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
